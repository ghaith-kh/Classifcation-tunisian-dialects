{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018149,
     "end_time": "2020-12-19T20:48:36.060477",
     "exception": false,
     "start_time": "2020-12-19T20:48:36.042328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The main aim of this notebook is overview of Electra base with Tunisian dialects*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:36.101909Z",
     "iopub.status.busy": "2020-12-19T20:48:36.101257Z",
     "iopub.status.idle": "2020-12-19T20:48:36.117082Z",
     "shell.execute_reply": "2020-12-19T20:48:36.116497Z"
    },
    "papermill": {
     "duration": 0.039822,
     "end_time": "2020-12-19T20:48:36.117205",
     "exception": false,
     "start_time": "2020-12-19T20:48:36.077383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tunisiandialects/sampletn_submission.csv\n",
      "/kaggle/input/tunisiandialects/test_tunDialect.xlsx\n",
      "/kaggle/input/tunisiandialects/Train_tunDialect.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:36.159686Z",
     "iopub.status.busy": "2020-12-19T20:48:36.159002Z",
     "iopub.status.idle": "2020-12-19T20:48:37.812639Z",
     "shell.execute_reply": "2020-12-19T20:48:37.813390Z"
    },
    "papermill": {
     "duration": 1.677998,
     "end_time": "2020-12-19T20:48:37.813611",
     "exception": false,
     "start_time": "2020-12-19T20:48:36.135613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:37.860533Z",
     "iopub.status.busy": "2020-12-19T20:48:37.859585Z",
     "iopub.status.idle": "2020-12-19T20:48:39.991540Z",
     "shell.execute_reply": "2020-12-19T20:48:39.990948Z"
    },
    "papermill": {
     "duration": 2.157492,
     "end_time": "2020-12-19T20:48:39.991674",
     "exception": false,
     "start_time": "2020-12-19T20:48:37.834182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=dt=pd.read_excel(\"../input/tunisiandialects/Train_tunDialect.xlsx\")\n",
    "df_test=pd.read_excel(\"../input/tunisiandialects/test_tunDialect.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.041320Z",
     "iopub.status.busy": "2020-12-19T20:48:40.040381Z",
     "iopub.status.idle": "2020-12-19T20:48:40.048677Z",
     "shell.execute_reply": "2020-12-19T20:48:40.049161Z"
    },
    "papermill": {
     "duration": 0.03973,
     "end_time": "2020-12-19T20:48:40.049277",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.009547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[المجلس الأعلى للأمن الجزائر برئاسة الرئيس عبد...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[سنتخذ إجراءات لحماية حدودنا وإقليمنا وسنفعل د...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[الصين تطلق الصاروخ الفضائي القوي (longue marc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[المصدرfrance 24]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[هذا عام ينقصي أعمارنا وعام يقبل علينا فماذا ف...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  [المجلس الأعلى للأمن الجزائر برئاسة الرئيس عبد...       1\n",
       "1  [سنتخذ إجراءات لحماية حدودنا وإقليمنا وسنفعل د...       1\n",
       "2  [الصين تطلق الصاروخ الفضائي القوي (longue marc...       1\n",
       "3                                  [المصدرfrance 24]       1\n",
       "4  [هذا عام ينقصي أعمارنا وعام يقبل علينا فماذا ف...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.103106Z",
     "iopub.status.busy": "2020-12-19T20:48:40.097866Z",
     "iopub.status.idle": "2020-12-19T20:48:40.739165Z",
     "shell.execute_reply": "2020-12-19T20:48:40.738632Z"
    },
    "papermill": {
     "duration": 0.671736,
     "end_time": "2020-12-19T20:48:40.739297",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.067561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    \n",
    "    text=\" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_test['text'] = df_test['text'].apply(preprocess)\n",
    "df_train=df_train[df_train[\"text\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.792426Z",
     "iopub.status.busy": "2020-12-19T20:48:40.791086Z",
     "iopub.status.idle": "2020-12-19T20:48:40.794777Z",
     "shell.execute_reply": "2020-12-19T20:48:40.795257Z"
    },
    "papermill": {
     "duration": 0.037009,
     "end_time": "2020-12-19T20:48:40.795387",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.758378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ longue marche5 37 ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france 24]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[ ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  target\n",
       "0                     [ ]       1\n",
       "1                     [ ]       1\n",
       "2   [ longue marche5 37 ]       1\n",
       "3             [france 24]       1\n",
       "4                     [ ]       1\n",
       "..                    ...     ...\n",
       "95                    [ ]       1\n",
       "96                    [ ]       1\n",
       "97                    [ ]       1\n",
       "98                    [ ]       1\n",
       "99                    [ ]       1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df_train[[\"text\",\"target\"]]\n",
    "df_train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.839657Z",
     "iopub.status.busy": "2020-12-19T20:48:40.838711Z",
     "iopub.status.idle": "2020-12-19T20:48:40.846591Z",
     "shell.execute_reply": "2020-12-19T20:48:40.846107Z"
    },
    "papermill": {
     "duration": 0.031978,
     "end_time": "2020-12-19T20:48:40.846696",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.814718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22999\n",
       "0     3819\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.895026Z",
     "iopub.status.busy": "2020-12-19T20:48:40.894119Z",
     "iopub.status.idle": "2020-12-19T20:48:40.896494Z",
     "shell.execute_reply": "2020-12-19T20:48:40.897042Z"
    },
    "papermill": {
     "duration": 0.028367,
     "end_time": "2020-12-19T20:48:40.897171",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.868804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = df_train.text.values\n",
    "labels = df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:48:40.943387Z",
     "iopub.status.busy": "2020-12-19T20:48:40.942662Z",
     "iopub.status.idle": "2020-12-19T20:49:18.096157Z",
     "shell.execute_reply": "2020-12-19T20:49:18.095174Z"
    },
    "papermill": {
     "duration": 37.178879,
     "end_time": "2020-12-19T20:49:18.096272",
     "exception": false,
     "start_time": "2020-12-19T20:48:40.917393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fa6b9a3ccf4669a418fd3a5020ec6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2a6708d0184281bc9ce699e92ec2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c626c78a90104afcb32969e482640461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440343552.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n",
    "import torch\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:18.174193Z",
     "iopub.status.busy": "2020-12-19T20:49:18.163781Z",
     "iopub.status.idle": "2020-12-19T20:49:22.779618Z",
     "shell.execute_reply": "2020-12-19T20:49:22.778501Z"
    },
    "papermill": {
     "duration": 4.658644,
     "end_time": "2020-12-19T20:49:22.779745",
     "exception": false,
     "start_time": "2020-12-19T20:49:18.121101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAE9CAYAAACStrEqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcsElEQVR4nO3dfdSldV3v8fcHQUKUJxk4NICDiHlQC3UOabgMpRQxhQwKTykZyynFIx47Z4meUlosEuuoRQlJS4+jKYQYgjyYiAiZCAwPOjyIjDDpBAEmCViMAt/zx/7t2HNzP1z3MHvf3HO9X2vtdV/7t6+H7/7NBffn/l1PqSokSVL/bLHQBUiSpIVhCJAkqacMAZIk9ZQhQJKknjIESJLUU4YASZJ6asuFLmDSdt5551q2bNlClyFJ0kRcffXV36+qJdN91rsQsGzZMlatWrXQZUiSNBFJ/mmmzzwcIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk91btnB2xqy447v/O8a0961RgrkSRpfhwJkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPTW2EJBkjySXJLkpyQ1Jjm3tOyW5KMkt7eeOI8u8K8maJDcnecVI+wuSrG6fnZwkrX3rJH/b2q9Ismxc30eSpM3NOEcCHgR+v6r+K/BC4Jgk+wLHARdX1T7Axe097bMjgWcDBwOnJHlCW9epwApgn/Y6uLUfDdxTVc8APgS8f4zfR5KkzcrYQkBV3VFV17Tp+4CbgKXAocDKNttK4LA2fShwRlWtr6rbgDXA/kl2A7arqsurqoBPTFlmuK6zgIOGowSSJGl2EzknoA3TPw+4Ati1qu6AQVAAdmmzLQW+N7LYuta2tE1Pbd9gmap6EPgh8NRptr8iyaokq+6+++5N86UkSVrkxh4CkjwZ+Czw9qq6d7ZZp2mrWdpnW2bDhqrTqmp5VS1fsmTJXCVLktQLYw0BSbZiEAA+VVV/15rvbEP8tJ93tfZ1wB4ji+8O3N7ad5+mfYNlkmwJbA/8YNN/E0mSNj/jvDogwEeBm6rqgyMfnQsc1aaPAs4ZaT+ynfG/F4MTAK9shwzuS/LCts43TFlmuK7DgS+38wYkSdIcthzjug8AXg+sTnJda3s3cBJwZpKjge8CRwBU1Q1JzgRuZHBlwTFV9VBb7s3Ax4FtgAvbCwYh45NJ1jAYAThyjN9HkqTNythCQFV9lemP2QMcNMMyJwInTtO+CnjONO0P0EKEJEmaH+8YKElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9Na8QkGSLJNuNqxhJkjQ5c4aAJJ9Osl2SbYEbgZuT/O/xlyZJksapy0jAvlV1L3AYcAGwJ/D6sVYlSZLGrksI2CrJVgxCwDlV9ZMx1yRJkiagSwj4CLAW2Ba4LMnTgB+OsyhJkjR+XULA56tqaVUdUlUFfBf4nTHXJUmSxqxLCPjs6JsWBM4YTzmSJGlStpzpgyTPAp4NbJ/ktSMfbQf81LgLkyRJ4zVjCAB+BvgVYAfg1SPt9wFvGmdRkiRp/GYMAVV1DnBOkhdV1eUTrEmSJE3AbCMBQ2uSvBtYNjp/VXlyoCRJi1iXEHAO8A/Al4CHxluOJEmalC4h4ElV9c6xVyJJkiaqyyWC5yU5ZOyVSJKkieoSAo5lEAQeSHJvkvuS3DvuwiRJ0njNeTigqp4yiUIkSdJkdXmUcJL8VpI/bO/3SLL/+EuTJEnj1OVwwCnAi4D/3t7fD3x4bBVJkqSJ6HJ1wM9X1fOTXAtQVfckeeKY65IkSWPWZSTgJ0meABRAkiXAw3MtlORjSe5Kcv1I2/FJ/jnJde11yMhn70qyJsnNSV4x0v6CJKvbZycnSWvfOsnftvYrkizr/K0lSVKnEHAycDawS5ITga8Cf9xhuY8DB0/T/qGq2q+9LgBIsi9wJIMHFh0MnNKCB8CpwApgn/YarvNo4J6qegbwIeD9HWqSJElNl6sDPpXkauAgIMBhVXVTh+Uum8df54cCZ1TVeuC2JGuA/ZOsBbYbPrsgySeAw4AL2zLHt+XPAv4ySdqjjiVJ0hy6jAQA3Mng1sFfA7ZJ8vzHsM23JvlmO1ywY2tbCnxvZJ51rW1pm57avsEyVfUg8EPgqY+hLkmSemXOkYAkJwC/DXyHdl5A+/myjdjeqcAJbfkTgA8Av8NghGGqmqWdOT7bQJIVDA4psOeee86vYkmSNlNdrg74dWDvqvrxY91YVd05nE7y18B57e06YI+RWXcHbm/tu0/TPrrMuiRbAtsDP5hhu6cBpwEsX77cwwWSJNHtcMD1wA6bYmNJdht5+6tt3QDnAke2M/73YnAC4JVVdQdwX5IXtqsC3sDgqYbDZY5q04cDX/Z8AEmSuusyEvA+4Np2qd/6YWNVvWa2hZKcDhwI7JxkHfBe4MAk+zEYtl8L/G5b1w1JzgRuBB4Ejqmq4WOL38zgSoNtGJwQeGFr/yjwyXYS4Q8YXF0gSZI66hICVjK4/G41He4PMFRVr5um+aOzzH8icOI07auA50zT/gBwRNd6JEnShrqEgO9X1cljr0SSJE1UlxBwdZL3MTgGP3o44JqxVSVJksauSwh4Xvv5wpG2jb1EUJIkPU50uWPgSydRiCRJmqwuNwvagcGlectG56+qt42vLEmSNG5dDgdcAHydeV4dIEmSHt+6hICfqqp3jL0SSZI0UV3uGPjJJG9KsluSnYavsVcmSZLGqstIwI+BPwX+Dxs+QOjp4ypKkiSNX5cQ8A7gGVX1/XEXI0mSJqfL4YAbgH8fdyGSJGmyuowEPARcl+QSNrxjoJcISpK0iHUJAZ9rL0mStBnpcsfAlUmeCDyzNd1cVT8Zb1mSJGncutwx8EAGjxNeCwTYI8lRVXXZeEuTJEnj1OVwwAeAl1fVzQBJngmcDrxgnIVJkqTx6nJ1wFbDAABQVd8GthpfSZIkaRK6jASsSvJR4JPt/W8BV4+vJEmSNAldQsCbgWOAtzE4J+BS4NRxFiVJksZvxhCQZAmwpKpuBD7YXiR5DrAdcPdEKpQkSWMx2zkBfwEsmaZ9KfDn4ylHkiRNymwh4LlVdenUxqr6e+Bnx1eSJEmahNlCwGxXAHh1gCRJi9xsIeCWJIdMbUzySuDW8ZUkSZImYbarA/4ncF6SX+eRSwKXAy8CfmXchUmSpPGacSSg3RTouQwuCVzWXpcCP9s+kyRJi9is9wmoqvXA/5tQLZIkaYK63DZYkiRthgwBkiT11IwhIMnF7ef7J1eOJEmalNnOCdgtyS8Cr0lyBoPnBvynqrpmrJVJkqSxmi0EvAc4Dtid9tyAEQW8bFxFSZKk8ZsxBFTVWcBZSf6wqk6YYE2SJGkC5nyUcFWdkOQ1wEta01eq6rzxliVJksZtzqsDkrwPOBa4sb2ObW2SJGkRm3MkAHgVsF9VPQyQZCVwLfCucRYmSZLGq+t9AnYYmd5+HIVIkqTJ6jIS8D7g2iSXMLhM8CU4CiBJ0qLX5cTA05N8BfhvDELAO6vqX8ZdmCRJGq8uIwFU1R3AuWOuRZIkTZDPDpAkqacMAZIk9dSsISDJFkmun1QxkiRpcmYNAe3eAN9IsueE6pEkSRPS5cTA3YAbklwJ/GjYWFWvGVtVkiRp7LqEgD8aexWSJGniutwn4NIkTwP2qaovJXkS8ITxlyZJksapywOE3gScBXykNS0FPtdhuY8luWv0xMIkOyW5KMkt7eeOI5+9K8maJDcnecVI+wuSrG6fnZwkrX3rJH/b2q9Isqzrl5YkSd0uETwGOAC4F6CqbgF26bDcx4GDp7QdB1xcVfsAF7f3JNkXOBJ4dlvmlCTD0YZTgRXAPu01XOfRwD1V9QzgQ8D7O9QkSZKaLiFgfVX9ePgmyZZAzbVQVV0G/GBK86HAyja9EjhspP2MqlpfVbcBa4D9k+wGbFdVl1dVAZ+YssxwXWcBBw1HCSRJ0ty6hIBLk7wb2CbJLwOfAT6/kdvbtd2CeHgr4uGIwlLgeyPzrWttS9v01PYNlqmqB4EfAk/dyLokSeqdLiHgOOBuYDXwu8AFwB9s4jqm+wu+ZmmfbZlHrzxZkWRVklV33333RpYoSdLmpcvVAQ8nWQlcweCX7M1taH5j3Jlkt6q6ow3139Xa1wF7jMy3O3B7a999mvbRZda1QxTb8+jDD8PvcBpwGsDy5cs3tnZJkjYrXa4OeBXwHeBk4C+BNUleuZHbOxc4qk0fBZwz0n5kO+N/LwYnAF7ZDhncl+SF7Xj/G6YsM1zX4cCXH0M4kSSpd7rcLOgDwEurag1Akr2B84ELZ1soyenAgcDOSdYB7wVOAs5McjTwXeAIgKq6IcmZwI3Ag8AxVfVQW9WbGVxpsE3b5nC7HwU+mWQNgxGAIzt8F0mS1HQJAXcNA0BzK48M48+oql43w0cHzTD/icCJ07SvAp4zTfsDtBAhSZLmb8YQkOS1bfKGJBcAZzI4J+AI4KoJ1CZJksZotpGAV49M3wn8Ypu+G9jx0bNLkqTFZMYQUFVvnGQhkiRpsuY8J6Cdrf8/gGWj8/soYUmSFrcuJwZ+jsGZ+J8HHh5vOZIkaVK6hIAHqurksVciSZImqksI+PMk7wW+CKwfNlbVNWOrSpIkjV2XEPBc4PXAy3jkcEC195IkaZHqEgJ+FXj66OOEJUnS4tflKYLfAHYYdyGSJGmyuowE7Ap8K8lVbHhOgJcISpK0iHUJAe8dexWSJGni5gwBVXXpJAqRJEmT1eWOgfcxuBoA4InAVsCPqmq7cRYmSZLGq8tIwFNG3yc5DNh/bBVJkqSJ6HJ1wAaq6nN4jwBJkha9LocDXjvydgtgOY8cHpAkSYtUl6sDXj0y/SCwFjh0LNVIkqSJ6XJOwBsnUYgkSZqsGUNAkvfMslxV1QljqEeSJE3IbCMBP5qmbVvgaOCpgCFAkqRFbMYQUFUfGE4neQpwLPBG4AzgAzMtJ0mSFodZzwlIshPwDuA3gZXA86vqnkkUJkmSxmu2cwL+FHgtcBrw3Kq6f2JVSZKksZvtZkG/D/w08AfA7Unuba/7ktw7mfIkSdK4zHZOwLzvJihJkhYPf9FLktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6qkFCQFJ1iZZneS6JKta205JLkpyS/u548j870qyJsnNSV4x0v6Ctp41SU5OkoX4PpIkLUYLORLw0qrar6qWt/fHARdX1T7Axe09SfYFjgSeDRwMnJLkCW2ZU4EVwD7tdfAE65ckaVF7PB0OOBRY2aZXAoeNtJ9RVeur6jZgDbB/kt2A7arq8qoq4BMjy0iSpDksVAgo4ItJrk6yorXtWlV3ALSfu7T2pcD3RpZd19qWtump7ZIkqYMtF2i7B1TV7Ul2AS5K8q1Z5p3uOH/N0v7oFQyCxgqAPffcc761SpK0WVqQkYCqur39vAs4G9gfuLMN8dN+3tVmXwfsMbL47sDtrX33adqn295pVbW8qpYvWbJkU34VSZIWrYmHgCTbJnnKcBp4OXA9cC5wVJvtKOCcNn0ucGSSrZPsxeAEwCvbIYP7krywXRXwhpFlJEnSHBbicMCuwNntar4tgU9X1ReSXAWcmeRo4LvAEQBVdUOSM4EbgQeBY6rqobauNwMfB7YBLmwvSZLUwcRDQFXdCvzcNO3/Chw0wzInAidO074KeM6mrlGSpD54PF0iKEmSJsgQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ4yBEiS1FOGAEmSesoQIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ7acqEL6JNlx53fab61J71qzJVIkuRIgCRJvWUIkCSppwwBkiT1lCFAkqSeMgRIktRThgBJknrKECBJUk8ZAiRJ6ilDgCRJPWUIkCSpp7xt8OOQtxeWJE2CIwGSJPWUIUCSpJ4yBEiS1FOeE7CIee6AJOmxWPQjAUkOTnJzkjVJjlvoeiRJWiwW9UhAkicAHwZ+GVgHXJXk3Kq6cWEre3xxxECSNJ3FPhKwP7Cmqm6tqh8DZwCHLnBNkiQtCot6JABYCnxv5P064OcXqJZFr+uIwULqOlrh6IckzW2xh4BM01aPmilZAaxob+9PcvNj3O7OwPcf4zr6YJP3U96/Kde26de3kdyfurGfurGf5ta3PnraTB8s9hCwDthj5P3uwO1TZ6qq04DTNtVGk6yqquWban2bK/upG/upG/upG/tpbvbRIxb7OQFXAfsk2SvJE4EjgXMXuCZJkhaFRT0SUFUPJnkr8PfAE4CPVdUNC1yWJEmLwqIOAQBVdQFwwYQ3u8kOLWzm7Kdu7Kdu7Kdu7Ke52UdNqh51Hp0kSeqBxX5OgCRJ2kiGgHnyNsUzS7I2yeok1yVZ1dp2SnJRklvazx0Xus5JS/KxJHcluX6kbcZ+SfKutn/dnOQVC1P1ZM3QR8cn+ee2P12X5JCRz3rXRwBJ9khySZKbktyQ5NjW7v40YpZ+cp+awsMB89BuU/xtRm5TDLzO2xQPJFkLLK+q74+0/Qnwg6o6qYWmHavqnQtV40JI8hLgfuATVfWc1jZtvyTZFzidwd0wfxr4EvDMqnpogcqfiBn66Hjg/qr6v1Pm7WUfASTZDditqq5J8hTgauAw4Ldxf/pPs/TTr+M+tQFHAubH2xTP36HAyja9ksF/iL1SVZcBP5jSPFO/HAqcUVXrq+o2YA2D/W6zNkMfzaSXfQRQVXdU1TVt+j7gJgZ3TnV/GjFLP82kl/0EhoD5mu42xbPtWH1TwBeTXN3u0giwa1XdAYP/MIFdFqy6x5eZ+sV9bENvTfLNdrhgOMRtHwFJlgHPA67A/WlGU/oJ3Kc2YAiYn063Ke6xA6rq+cArgWPaEK/mx33sEacCewP7AXcAH2jtve+jJE8GPgu8varunW3Wadp601fT9JP71BSGgPnpdJvivqqq29vPu4CzGQyn3dmOzw2P0921cBU+rszUL+5jTVXdWVUPVdXDwF/zyPBsr/soyVYMfrF9qqr+rjW7P00xXT+5Tz2aIWB+vE3xDJJs207AIcm2wMuB6xn0z1FttqOAcxamwsedmfrlXODIJFsn2QvYB7hyAepbcMNfas2vMtifoMd9lCTAR4GbquqDIx+5P42YqZ/cpx5t0d8xcJK8TfGsdgXOHvy3x5bAp6vqC0muAs5McjTwXeCIBaxxQSQ5HTgQ2DnJOuC9wElM0y9VdUOSM4EbgQeBY/pwhvIMfXRgkv0YDMuuBX4X+ttHzQHA64HVSa5rbe/G/Wmqmfrpde5TG/ISQUmSesrDAZIk9ZQhQJKknjIESJLUU4YASZJ6yhAgSVJPGQKkDpLcP+b1vz3JkzbF9tq1zl9qT0n7jWk+/19JvpXk+iTfSPKGjd3WuCXZIclbZvn8oZEnwl2XeTzZM8mBSc57DLXNuHwGT9TcuU1/bWO3IY2b9wmQHh/eDvwN8O+bYF3PA7aqqv2mfpDk9xg8BXP/qro3yfY8vh/qtAPwFuCUGT7/j+m+5+NJVf3CQtcgzcSRAGkjJdk7yRfaA5P+IcmzWvvHk5yc5GtJbk1yeGvfIskpGTzf/LwkFyQ5PMnbGDy+9JIkl4ys/8T2l/rXk+w6zfZ3SvK59jCUryf52SS7MAgT+7W/jPeesti7gbcM7zdfVT+sqpVtfQcluTbJ6vZwla1b+9okf5zk8iSrkjw/yd8n+U4LFcO/ii9NcmaSbyc5KclvJrmyrW/vNt+SJJ9NclV7HdDaj2/b/Errs7e1ek8C9m7f5U/n8W8zZ83NdknOTnJjkr9KskVb/uVt2WuSfCaDe9CT5OA2ivJV4LUj23tqki+2/vsII/eiH47qtD76SpKz2jo+lQzurpXkkOF6275zXmv/xZFRjmvT7sopbTJV5cuXrzleDJ5BPrXtYmCfNv3zwJfb9MeBzzAI2fsyePw0wOHABa39vwD3AIe3z9YCO4+su4BXt+k/Af5gmu3/BfDeNv0y4Lo2fSBw3jTzPwW4Z4bv91MMnqL2zPb+EwweujKs7c1t+kPAN9u6lgB3jWzz34DdgK2Bfwb+qH12LPBnbfrTwIvb9J4MbusKcDzwtbbszsC/AlsBy4DrZ/l3eQi4buT1G/Os+QHg6QzuAHpR+zfaGbgM2LbN907gPSN9tA+DX/JnDvsZOBl4T5t+Vfv323l032nb+yGD+9JvAVwOvHhkvXu1+U4fWe/nGTyYC+DJwJYL/d+Cr83r5eEAaSO0vwx/AfhM+2MOBr/Ahj5Xg4eU3DjyV/yLgc+09n8Z/at/Gj8Ghsebr2YwhD/Vi4FfA6iqL7e/RrefrWxmfjLazwC3VdW32/uVwDHAn7X3w2dkrAaeXINntN+X5IEkO7TPrqr2ONsk3wG+OLLMS9v0LwH7jvTZdiN/3Z5fVeuB9UnuYnAr6rnMdjigS81XVtWtrebTGfTpAwzC2z+2Op/I4Bf2sxj00S1t/r8Bho/MfgltZKCqzk9yzww1XVlV69ry1zEIOfcDt9bgOfYwCAHD9f4j8MEknwL+bristKkYAqSNswXwb7P8Alo/Mp0pP7v4SVUNf2E/xPT/rc7r8ac1OAfgR0mePvzFN8e6Rg2/z8Ns+N0eHqltavv6aebZAnhRVf3HBhsf/LIdXX6m7zwfXWqe2l/FoC8uqqrXTalxv2nmn7ps15rgke84Y99X1UlJzgcOAb6e5Jeq6lsdtiN14jkB0kaowTH125IcAYOnliX5uTkW+yrwaxmcG7Arg+HhofsYDFfPx2XAb7btHwh8v2Z/tjzA+4APJ9muLbddkhXAt4BlSZ7R5ns9cOk86+nii8Bbh2/aL9bZbEy/zMf+GTwVdAvgNxj8G30dOGDYF0melOSZDPpor5HzLEZDwui/xSuBHedRw7eApydZ1t7/5xUdSfauqtVV9X5gFYPRCGmTMQRI3TwpybqR1zsY/E//6CTfAG4ADp1jHZ9l8Nzy64GPAFcwOEYMcBpw4RyHCKY6Hlie5JsMTqA7avbZATgVuAS4Ksn1DH7R/3tVPQC8kcHhjdUM/lr+q3nU0tXbhjUnuRH4vdlmrqp/ZTAsf/0MJwZukw0vETxpnvVczqDvrgduA86uqruB3wZOb337deBZrY9WAOe3EwP/aWQ9fwS8JMk1DB6j/d2uBbRRkbcAX2jrvZNH9ou3t+/+DeA/gAvn+f2kWfkUQWmCkjy5qu5P8lQGzys/oKr+ZaHr0sIa2S8CfBi4pao+tNB1afPnOQHSZJ3XTkp7InCCAUDNm5IcxWC/uJbBSJE0do4ESJLUU54TIElSTxkCJEnqKUOAJEk9ZQiQJKmnDAGSJPWUIUCSpJ76/2RhBvtJOY0KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to show length of embedding will be helpful to determine maximum length of texts and padding threshold\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
    "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5));\n",
    "    ax.hist(tokenized_texts_len, bins=40);\n",
    "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
    "    ax.set_ylabel(\"Number of Comments\");\n",
    "    return\n",
    "plot_sentence_embeddings_length(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02588,
     "end_time": "2020-12-19T20:49:22.835077",
     "exception": false,
     "start_time": "2020-12-19T20:49:22.809197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It seems almost all comments have less than 50 tokens, therefore instead of 512, we can set maximum length as 64**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:22.892606Z",
     "iopub.status.busy": "2020-12-19T20:49:22.892006Z",
     "iopub.status.idle": "2020-12-19T20:49:29.131032Z",
     "shell.execute_reply": "2020-12-19T20:49:29.129711Z"
    },
    "papermill": {
     "duration": 6.270336,
     "end_time": "2020-12-19T20:49:29.131179",
     "exception": false,
     "start_time": "2020-12-19T20:49:22.860843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "\n",
    "input_ids=indices[\"input_ids\"]\n",
    "attention_masks=indices[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.231117Z",
     "iopub.status.busy": "2020-12-19T20:49:29.230224Z",
     "iopub.status.idle": "2020-12-19T20:49:29.245840Z",
     "shell.execute_reply": "2020-12-19T20:49:29.245341Z"
    },
    "papermill": {
     "duration": 0.07602,
     "end_time": "2020-12-19T20:49:29.245938",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.169918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 99% for training and 1% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.548077Z",
     "iopub.status.busy": "2020-12-19T20:49:29.509654Z",
     "iopub.status.idle": "2020-12-19T20:49:29.562367Z",
     "shell.execute_reply": "2020-12-19T20:49:29.561811Z"
    },
    "papermill": {
     "duration": 0.289968,
     "end_time": "2020-12-19T20:49:29.562473",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.272505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.624066Z",
     "iopub.status.busy": "2020-12-19T20:49:29.623362Z",
     "iopub.status.idle": "2020-12-19T20:49:29.626488Z",
     "shell.execute_reply": "2020-12-19T20:49:29.626999Z"
    },
    "papermill": {
     "duration": 0.037466,
     "end_time": "2020-12-19T20:49:29.627144",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.589678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.692366Z",
     "iopub.status.busy": "2020-12-19T20:49:29.691304Z",
     "iopub.status.idle": "2020-12-19T20:49:29.694553Z",
     "shell.execute_reply": "2020-12-19T20:49:29.694044Z"
    },
    "papermill": {
     "duration": 0.040926,
     "end_time": "2020-12-19T20:49:29.694673",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.653747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 6e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.757584Z",
     "iopub.status.busy": "2020-12-19T20:49:29.756507Z",
     "iopub.status.idle": "2020-12-19T20:49:29.759663Z",
     "shell.execute_reply": "2020-12-19T20:49:29.759091Z"
    },
    "papermill": {
     "duration": 0.036324,
     "end_time": "2020-12-19T20:49:29.759758",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.723434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.820260Z",
     "iopub.status.busy": "2020-12-19T20:49:29.819381Z",
     "iopub.status.idle": "2020-12-19T20:49:29.821707Z",
     "shell.execute_reply": "2020-12-19T20:49:29.822200Z"
    },
    "papermill": {
     "duration": 0.035908,
     "end_time": "2020-12-19T20:49:29.822320",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.786412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T20:49:29.939810Z",
     "iopub.status.busy": "2020-12-19T20:49:29.938906Z",
     "iopub.status.idle": "2020-12-19T21:02:26.917348Z",
     "shell.execute_reply": "2020-12-19T21:02:26.916430Z"
    },
    "papermill": {
     "duration": 777.029213,
     "end_time": "2020-12-19T21:02:26.917463",
     "exception": false,
     "start_time": "2020-12-19T20:49:29.888250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    671.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    671.    Elapsed: 0:00:24.\n",
      "  Batch   150  of    671.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    671.    Elapsed: 0:00:47.\n",
      "  Batch   250  of    671.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    671.    Elapsed: 0:01:10.\n",
      "  Batch   350  of    671.    Elapsed: 0:01:21.\n",
      "  Batch   400  of    671.    Elapsed: 0:01:33.\n",
      "  Batch   450  of    671.    Elapsed: 0:01:44.\n",
      "  Batch   500  of    671.    Elapsed: 0:01:56.\n",
      "  Batch   550  of    671.    Elapsed: 0:02:08.\n",
      "  Batch   600  of    671.    Elapsed: 0:02:19.\n",
      "  Batch   650  of    671.    Elapsed: 0:02:31.\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epoch took: 0:02:36\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    671.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    671.    Elapsed: 0:00:23.\n",
      "  Batch   150  of    671.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    671.    Elapsed: 0:00:47.\n",
      "  Batch   250  of    671.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    671.    Elapsed: 0:01:10.\n",
      "  Batch   350  of    671.    Elapsed: 0:01:22.\n",
      "  Batch   400  of    671.    Elapsed: 0:01:34.\n",
      "  Batch   450  of    671.    Elapsed: 0:01:45.\n",
      "  Batch   500  of    671.    Elapsed: 0:01:57.\n",
      "  Batch   550  of    671.    Elapsed: 0:02:08.\n",
      "  Batch   600  of    671.    Elapsed: 0:02:20.\n",
      "  Batch   650  of    671.    Elapsed: 0:02:31.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epoch took: 0:02:36\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    671.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    671.    Elapsed: 0:00:23.\n",
      "  Batch   150  of    671.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    671.    Elapsed: 0:00:46.\n",
      "  Batch   250  of    671.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    671.    Elapsed: 0:01:10.\n",
      "  Batch   350  of    671.    Elapsed: 0:01:21.\n",
      "  Batch   400  of    671.    Elapsed: 0:01:33.\n",
      "  Batch   450  of    671.    Elapsed: 0:01:44.\n",
      "  Batch   500  of    671.    Elapsed: 0:01:56.\n",
      "  Batch   550  of    671.    Elapsed: 0:02:08.\n",
      "  Batch   600  of    671.    Elapsed: 0:02:20.\n",
      "  Batch   650  of    671.    Elapsed: 0:02:31.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epoch took: 0:02:36\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    671.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    671.    Elapsed: 0:00:23.\n",
      "  Batch   150  of    671.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    671.    Elapsed: 0:00:46.\n",
      "  Batch   250  of    671.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    671.    Elapsed: 0:01:09.\n",
      "  Batch   350  of    671.    Elapsed: 0:01:21.\n",
      "  Batch   400  of    671.    Elapsed: 0:01:32.\n",
      "  Batch   450  of    671.    Elapsed: 0:01:44.\n",
      "  Batch   500  of    671.    Elapsed: 0:01:55.\n",
      "  Batch   550  of    671.    Elapsed: 0:02:07.\n",
      "  Batch   600  of    671.    Elapsed: 0:02:18.\n",
      "  Batch   650  of    671.    Elapsed: 0:02:30.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epoch took: 0:02:35\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    671.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    671.    Elapsed: 0:00:23.\n",
      "  Batch   150  of    671.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    671.    Elapsed: 0:00:46.\n",
      "  Batch   250  of    671.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    671.    Elapsed: 0:01:10.\n",
      "  Batch   350  of    671.    Elapsed: 0:01:21.\n",
      "  Batch   400  of    671.    Elapsed: 0:01:32.\n",
      "  Batch   450  of    671.    Elapsed: 0:01:44.\n",
      "  Batch   500  of    671.    Elapsed: 0:01:55.\n",
      "  Batch   550  of    671.    Elapsed: 0:02:07.\n",
      "  Batch   600  of    671.    Elapsed: 0:02:18.\n",
      "  Batch   650  of    671.    Elapsed: 0:02:30.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epoch took: 0:02:35\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "      \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T21:02:27.029259Z",
     "iopub.status.busy": "2020-12-19T21:02:27.025545Z",
     "iopub.status.idle": "2020-12-19T21:02:37.375721Z",
     "shell.execute_reply": "2020-12-19T21:02:37.376616Z"
    },
    "papermill": {
     "duration": 10.409178,
     "end_time": "2020-12-19T21:02:37.376852",
     "exception": false,
     "start_time": "2020-12-19T21:02:26.967674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:10\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "# After the completion of each training epoch, measure our performance on\n",
    "# our validation set.\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "model.eval()\n",
    "\n",
    "preds=[]\n",
    "true=[]\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up validation\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # This will return the logits rather than the loss because we have\n",
    "        # not provided labels.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    preds.append(logits)\n",
    "    true.append(label_ids)\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T21:02:37.539148Z",
     "iopub.status.busy": "2020-12-19T21:02:37.538346Z",
     "iopub.status.idle": "2020-12-19T21:02:37.547378Z",
     "shell.execute_reply": "2020-12-19T21:02:37.548192Z"
    },
    "papermill": {
     "duration": 0.093636,
     "end_time": "2020-12-19T21:02:37.548356",
     "exception": false,
     "start_time": "2020-12-19T21:02:37.454720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in preds for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T21:02:37.701510Z",
     "iopub.status.busy": "2020-12-19T21:02:37.700667Z",
     "iopub.status.idle": "2020-12-19T21:02:37.723201Z",
     "shell.execute_reply": "2020-12-19T21:02:37.724254Z"
    },
    "papermill": {
     "duration": 0.104057,
     "end_time": "2020-12-19T21:02:37.724412",
     "exception": false,
     "start_time": "2020-12-19T21:02:37.620355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.60      0.10        73\n",
      "           1       0.99      0.86      0.92      5291\n",
      "\n",
      "    accuracy                           0.86      5364\n",
      "   macro avg       0.53      0.73      0.51      5364\n",
      "weighted avg       0.98      0.86      0.91      5364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(flat_predictions,flat_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051134,
     "end_time": "2020-12-19T21:02:37.851660",
     "exception": false,
     "start_time": "2020-12-19T21:02:37.800526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making my submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T21:02:37.990654Z",
     "iopub.status.busy": "2020-12-19T21:02:37.975283Z",
     "iopub.status.idle": "2020-12-19T21:02:39.469264Z",
     "shell.execute_reply": "2020-12-19T21:02:39.468700Z"
    },
    "papermill": {
     "duration": 1.563794,
     "end_time": "2020-12-19T21:02:39.469383",
     "exception": false,
     "start_time": "2020-12-19T21:02:37.905589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments1 = df_test.text.values\n",
    "\n",
    "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n",
    "input_ids1=indices1[\"input_ids\"]\n",
    "attention_masks1=indices1[\"attention_mask\"]\n",
    "\n",
    "prediction_inputs1= torch.tensor(input_ids1)\n",
    "prediction_masks1 = torch.tensor(attention_masks1)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32 \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
    "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
    "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-19T21:02:39.586118Z",
     "iopub.status.busy": "2020-12-19T21:02:39.585155Z",
     "iopub.status.idle": "2020-12-19T21:03:02.626744Z",
     "shell.execute_reply": "2020-12-19T21:03:02.625537Z"
    },
    "papermill": {
     "duration": 23.104867,
     "end_time": "2020-12-19T21:03:02.626877",
     "exception": false,
     "start_time": "2020-12-19T21:02:39.522010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 6,000 test sentences...\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions = []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader1:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids1, b_input_mask1 = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs1 = model(b_input_ids1, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask1)\n",
    "\n",
    "  logits1 = outputs1[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits1 = logits1.detach().cpu().numpy()\n",
    "  \n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits1)\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 872.074489,
   "end_time": "2020-12-19T21:03:03.809947",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-19T20:48:31.735458",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05ac3c3e54384fb0934fe8a3b6d891da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_48f998afb2a9462f8cd2846bcf6c1c56",
       "placeholder": "​",
       "style": "IPY_MODEL_d602f6344edc40839b468701c550e0f0",
       "value": " 467/467 [00:00&lt;00:00, 1.48kB/s]"
      }
     },
     "1989494714e04ac68146607701d84117": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25f71a784ae64369a9cc3646dfb3cc60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38b78555618044f1b53b6329140dea83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a310e942987c496fa4cf41e520ac3f66",
       "placeholder": "​",
       "style": "IPY_MODEL_4485719794a948b0ba0a01505db84fc0",
       "value": " 232k/232k [00:00&lt;00:00, 2.38MB/s]"
      }
     },
     "422823e47bde4f65aa1f948bb315fba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4485719794a948b0ba0a01505db84fc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "48f998afb2a9462f8cd2846bcf6c1c56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a2a6708d0184281bc9ce699e92ec2bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a4a99869c6343cd97da819896dbb9b7",
        "IPY_MODEL_05ac3c3e54384fb0934fe8a3b6d891da"
       ],
       "layout": "IPY_MODEL_99a7b70147e44a1a95271a25176d6871"
      }
     },
     "4d751c9b361c4a5fb5cdd9b348d772ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5836621102c242718969c1477d955fe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7aa250bffdc54727b915d341a7b98322": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f55078e86b84f339250f01cdf37d96f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b399d5b00934d3b8629bbe9d3279182",
       "max": 440343552.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e524525966694f10bacbc7ebff4a4797",
       "value": 440343552.0
      }
     },
     "99a7b70147e44a1a95271a25176d6871": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a4a99869c6343cd97da819896dbb9b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4d751c9b361c4a5fb5cdd9b348d772ed",
       "max": 467.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c3d1fa9183564c26bf2a1374b762496f",
       "value": 467.0
      }
     },
     "9b399d5b00934d3b8629bbe9d3279182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a30fcc97a8a74cf0a6271fce62e9c603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5836621102c242718969c1477d955fe2",
       "placeholder": "​",
       "style": "IPY_MODEL_1989494714e04ac68146607701d84117",
       "value": " 440M/440M [00:18&lt;00:00, 23.4MB/s]"
      }
     },
     "a310e942987c496fa4cf41e520ac3f66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af3fb091619a4bfa8f8f6442163c62f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3d1fa9183564c26bf2a1374b762496f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c4fa6b9a3ccf4669a418fd3a5020ec6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fa5f7932de104c8b9a456afb53534977",
        "IPY_MODEL_38b78555618044f1b53b6329140dea83"
       ],
       "layout": "IPY_MODEL_25f71a784ae64369a9cc3646dfb3cc60"
      }
     },
     "c626c78a90104afcb32969e482640461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8f55078e86b84f339250f01cdf37d96f",
        "IPY_MODEL_a30fcc97a8a74cf0a6271fce62e9c603"
       ],
       "layout": "IPY_MODEL_7aa250bffdc54727b915d341a7b98322"
      }
     },
     "d602f6344edc40839b468701c550e0f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e524525966694f10bacbc7ebff4a4797": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fa5f7932de104c8b9a456afb53534977": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af3fb091619a4bfa8f8f6442163c62f6",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_422823e47bde4f65aa1f948bb315fba1",
       "value": 231508.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
